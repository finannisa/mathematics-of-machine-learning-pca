# Table of Contents
## Lectures
Principal Component Analysis is a form of dimensionality reduction. It analyses and then exploits the structure of the data and the correlations between the different variables within the data set.
The key goal of PCA is to achieve a more compact model with lower dimensions without losing vital information in the data set. 

Principal Component Analysis (PCA) is one of the most important dimensionality reduction algorithms in machine learning. In this course, we lay the mathematical foundations to derive and understand PCA from a geometric point of view. In this module, we learn how to summarize datasets (e.g., images) using basic statistics, such as the mean and the variance. We also look at properties of the mean and the variance when we shift or scale the original data set. We will provide mathematical intuition as well as the skills to derive the results. We will also implement our results in code (jupyter notebooks), which will allow us to practice our mathematical understand to compute averages of image data sets.     


## Assignments
- The Sandpit Part I ([Solution](https://github.com/jessxphil/mathematics-of-machine-learning-multivariate-calculus/blob/master/assignment-1/the-sandpit-part-1.ipynb))([Write up](https://medium.com/@jessxphil)) + The Sandpit Part II ([Solution](https://github.com/jessxphil/mathematics-of-machine-learning-multivariate-calculus/blob/master/assignment-1/the-sandpit-part-2.ipynb))([Write up](https://medium.com/@jessxphil))
- Back Propogation ([Solution](https://github.com/jessxphil/mathematics-of-machine-learning-multivariate-calculus/blob/master/assignment-2/i-heart-back-propagation.ipynb))([Write up](https://medium.com/@jessxphil))
- Fitting the Distribution of Heights Data ([Solution](https://github.com/jessxphil/mathematics-of-machine-learning-multivariate-calculus/blob/master/assignment-3/fitting-distribution-height-data.ipynb))([Write up](https://medium.com/@jessxphil))
